Zbalansowanie zbioru.
- Zbalasowanie zbioru odnosi się do sytuacji w której różne klasy z zbiorze mają podobną liczebność. Algorytmy uczące się na podstawie zbilansowanego zbioru nie skupiają sie na jednej klasie kosztem innych (model jest skuteczniejszy oraz się nie przeucza). Niezbalansowany zbiór to taki gdzie jedna klasa dominuje nad innymi. Model wytrenowany na niezbalanowanym zbiorze może mieć tendencje do przewidywania klasy która występuje częściej.

Miary oceny jakości klasyfikacji.
- narzędzia używane do ocenu skuteczności modelu klasyfikacyjnego na podstawie wyników predykcji.
* Dokładność (Accuracy): Poprawnie sklasyfikowane/Wszystkie
NIE RADZI SOBIE Z KLASAMI NIEZBALANSOWANYMI
* Precyzja (Precision): Dokładność pozytywnych predykcji - TP/(TP + FP)
* Czułość (Recall): Wykrywanie wszystkich pozytwnych przypadków
TP/(TP + FN)
* F1_SCORE (Średnia harmoniczna)
(2*Precision*Recall)/(Precision + Recall)

Miary oceny jakości regresji.
- Używane do ocenienia jak dobrze model przewiduje ciągłe wartości numeryczne
* Średni Błąd Kwadratowy (Mean Square Error - MSE)
MSE = 1/n*Sum_{i=1}^{n} (y_i - y^_i)^2
* Pierwiastek kwadratowy z MSE (Odchylenie standardowe reszt)

Podział zbioru danych na treningowy, testowy, walidacyjny.
- Tworząc model np. regresji liniowej dzialimy zbiór na treningowy oraz testowy. Zbiór treningowy pozwoli nam utworzyć model, testowy oszacować jego jakość. W przypadku tuningu hiperparametrów tworzymy również zbiór walidacyjny który ma sprawdzać jakość modelu dla różnych hiperparametrów. Zbiór walidacyjny wycina się ze zbioru treningowego. Najczęstsze proporcje 60/20/20 80/10/10

Hiperparametry treningu.
- Hiperparametr jest stałą narzucaną z góry przed treningiem.
Hiperparametr jest używany w regularyzacji modelu w celu penalizacji dużych wag w funkcji kosztu

Walidacja skrośna.
- Polega na tym że dzielimy zbiór na K równych podzbiorów (foldów) Każdy po polei staje się zbiorem walidacyjnym, a reszta połączonym zbiorem treningowym.

Regularyzacja: L1 i L2.
- Regresja L1 - LASSO dokonuje selekcji cech (feature selection)
L_LASSO(y, y^) = 1/n*(y-y^)^{2} + alpha*||w||_1
- Regresja L2 - RIDGE zmniejsza wagi i jest różniczkowalna
L_RIDGE(y, y^) = 1/n*(y-y^)^{2} + delta*||w||^{2}_{2}

Niedopasowanie (underfitting).
- Underfitting pojawia się gdy nasz model nie radzi sobie zarówno z danymi treningowymi jak i testowymi. Można to zauważyć sprawdzając wartość RMSE (pierwiastka kwadratowego z błędu średniokwadratowego) dla naszego modelu wartości te będą wysokie.

Nadmierne dopasowanie (overfitting).
-  Jeżeli model radzi sobie z danymi treningowymi lepiej od dancych testowym mamy overfitting - model skupił się na zapamiętywaniu konkretnych przykładów zamiast wyciąganiu z nich wzorców. Wartość błędu testowego duża wyższa od treningowego.
W celu poprawy modelu trzeba go regularyzować.

Regresja liniowa.
Służy do przewidywania wartości ciągłej
- model postaci y^ = ax + b,
y^ - zmienna niezależna,
x - zmienna zależna (wartość cechy)
Zalożenia:
* Liniowość, Normalność, Stała Wariancja, Niezależnosć błędów, Brak współliniowości zmiennych.

Regresja logistyczna a klasyfikacja.
- Pozwala na przewidywanie zmiennych w oparciu o jedną lub większą ilosć cech. Funkcją bazową jest funkcja logarytmiczna.

Obciążenie modelu uczenia maszynowego.
- Obciązenie modelu - tendencja hipotezy h do różnienia się od oczekiwanego wyniku (wartości oczekiwanej), w przypadku treningu na różnych zbiorach danych.

Wariancja modelu uczenia maszynowego.
- Zmienność wyniku funkcji wynikająca z (niewielkich) zmian w danych.

Konstrukcja i działanie drzew decyzyjnych.

Macierz pomyłek.
- Metryka opisująca sytuacje jakie mogą się zdarzyć przy klasyfikacji Binarnej

TP | FN
-------
FP | TN

TP Model: TRUE Actual TRUE
FP Model: TRUE Actual FALSE
TN Model: FALSE Actual FALSE
FN Model: FALSE Actual TRUE

Funkcja kosztu.

